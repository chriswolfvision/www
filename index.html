<!-- ****************************************************************************************
  Author: Christian Wolf
  ******************************************************************************************* -->

<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">

<html>
<head>
	<link rel=stylesheet href="main.css?v=1" type="text/css">
	<link rel=stylesheet href="portrait.css" type="text/css">
	<link rel=stylesheet href="lightfont.css" type="text/css">
	<link rel="shortcut icon" href="graphics/favicon.ico">
	<script type="text/javascript" language="JavaScript" src="ballonsv4.js"></script>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
  	<title>Christian Wolf, Naver Labs Europe</title>
</head>

<body>


<!-- ****************************************************************************************
  The hidden help field
  **************************************************************************************** -->

<!-- The box which contains the ballon help - hidden at the beginning -->
<div style="left: 50px; top: 0ex; position: absolute; border: 4px solid #44a3c0; background-color: #ffffff; padding: 1ex; visibility: hidden;" class="bulle-aide" id="bulle_aide">XXXXX</div>

<!-- ****************************************************************************************
  The nav menu box
  **************************************************************************************** -->

<!-- <a href="contribution/yosemite.html">
<img style="max-width: 100%; height: auto; width: auto\9;" src="miscphotos/chris_banner_usa2014_v2.jpg">
</a>
 -->



 

<!-- ****************************************************************************************
  The personal data
  **************************************************************************************** -->

<div class="block">

  	<!-- The Photo -->
	<div class="floater">
		<table>			
            <tr><td>
                <span title="Taken in June 2018 during post-conference vacation in the US.   ">
                    <img src="miscphotos/chris_milwaukee_longer.png">
                </span>
            </td></tr>
            <tr><td>
                <span class="aide" title="<b>arXiv</b><br>Learning to navigate efficiently and precisely in real environments<br>
                (Naver Rookie / Around at Naver Labs Europe, end-to-end trained agent)<br>
                Work by Guillaume Bono, Hervé Poirier, Leonid Antsfeld, Gianluca Monaci, Boris Chidlovskii, Christian Wolf<br><br><img width=100% src=graphics/big_fm09.jpg>">
                    <img src="graphics/animated_around2023.gif">
                </span>
            </td></tr>
            <tr><td style="padding-top: 1em;">
                <span class="aide" title="<b>ICLR 2024</b><br>  
End-to-End (Instance)-Image Goal Navigation through Correspondence as an Emergent Phenomenon<br>
                Work by Guillaume Bono, Leonid Antsfeld, Boris Chidlovskii, Philippe Weinzaepfel and Christian Wolf<br><br><br><img width=100% src=graphics/croconav_big.jpg>">
                    <img src="graphics/croconav_small.jpg">
                </span>
            </td></tr>
            <tr><td style="padding-top: 1em;">
            <span class="aide" title="<b>ICLR 2024</b><br> Learning with a Mole: Transferable latent spatial representations for navigation without reconstruction<br>Work by Guillaume Bono, Leonid Antsfeld, Assem Sadek, Gianluca Monaci and Christian Wolf<br><br>(Animation by Guillaume Bono)<br><img width=100% src=graphics/mole_big.jpg>">
                    <img src="graphics/animated_mole.gif">
                </span>
            </td></tr>
            <tr><td style="padding-top: 1em;">
            <span class="aide" title="<b>ICLR 2024 (spotlight)</b><br>Space and time continuous physics simulation from partial observations<br>Work by Steeven Janny, Madiha Nadri, Julie Digne and Christian Wolf<br><br>(Animation by Steeven Janny)<br><img width=100% src=graphics/big_pde2024.jpg>">
                    <img src="graphics/animated_pde2024.gif">
                </span>
            </td></tr>
            <tr><td style="padding-top: 1em;">
                <span class="aide" title="<b>3DV 2024 (spotlight)</b><br>Zero-BEV: Zero-shot Projection of any First-Person Modality to Bird’s-Eye-View Maps<br>
                Work by Gianluca Monaci, Leonid Antsfeld, Boris Chidlovskii, Christian Wolf<br><br><br><img width=100%>">
                    <img src="graphics/zerobev_small.jpg">
                </span>
            </td></tr>
            <tr><td style="padding-top: 1em;">
                <span class="aide" title="<b>ICLR 2023</b><br>  
EAGLE: Large-scale Learning of Turbulent Fluid Dynamics with Mesh Transformers<br>
                Work by Steeven Janny, Madiha Nadri, Julie Digne, Nicolas Thome and Christian Wolf<br><br>(Animation by Steeven Janny)<br><img width=100% src=graphics/eagle_big.jpg>">
                    <img src="graphics/animated_eagle2022.gif">
                </span>
            </td></tr>
            <tr><td style="padding-top: 1em;">
                <span class="aide" title="<b>ICCV 2023</b><br>Multi-Object Navigation with dynamically learned neural implicit representations<br>
                Work by Pierre Marza, Laetitia Matignon, Olivier Simonin and Christian Wolf<br><br><br><img width=100% src=graphics/pierrenerf_big.jpg>">
                    <img src="graphics/iccv2023.jpg">
                </span>
            </td></tr>            
            <tr><td style="padding-top: 1em;">
            <span class="aide" title="<b>arxiv:2304.11241</b><br>  
AutoNERF: Training Implicit Scene Representations with Autonomous Agents<br>
                Work by Pierre Marza, Laetitia Matignon, Oliver Simonin, Dhruv Batra, Christian Wolf and Devendra Singh Chaplot<br><br><br><img width=100% src=graphics/autonerf_big.jpg>">
                    <img src="graphics/animated_autonerf.gif">
                </span>
            </td></tr>
            <tr><td style="padding-top: 1em;">
                <span class="aide" title="<b>IROS 2023</b><br>Learning whom to trust in navigation: dynamically switching between classical and neural planning<br>Work by Sombit Dey, Assem Sadek, Gianluca Monaci, Boris Chidlovskii and Christian Wolf<br><br><br><img width=100% src=graphics/iros2023_big.jpg>">
                    <img src="graphics/iros2023.jpg">
                </span>
            </td></tr>   
            <tr><td style="padding-top: 1em;">
                <span class="aide" title="<b>ICRA 2023</b><br>Multi-Object Navigation in real environments using hybrid policies<br>Work by Assem Sadek, Guillaume Bono, Boris Chidlovskii, Atilla Baskurt and Christian Wolf<br><br><br><img width=100% src=graphics/icra2023big.jpg>">
                    <img src="graphics/animated_icra2023.gif">
                </span>
            </td></tr>               
            <tr><td style="padding-top: 1em;">
                <span class="aide" title="<b>ICLR 2022 (oral)</b><br>Filtered-CoPhy: Unsupervised Learning of Counterfactual Physics in Pixel Space<br>
                Work by Steeven Janny and Fabien Baradel and Natalia Neverova, Madiha Nadri, Greg Mori and Christian Wolf<br><br><br><img width=100% src=graphics/iclr2022big.jpg>">
                    <img src="graphics/iclr2022small2.png">
                </span>
            </td></tr>
            <tr><td style="padding-top: 1em;">
                <span class="aide" title="<b>IROS 2022<br>Winning entry of the CVPR 2021 Multi-Object Navigation Challenge</b><br>Teaching Agents how to map: Spatial Reasoning for Multi-Object Navigation<br>Work by Pierre Marza, Laetitia Matignon, Oliver Simonin and Christian Wolf<br><br>(Animation by Pierre Marza)<br><img width=100% src=graphics/multion_big.jpg>">
                    <img src="graphics/animated_multion.gif">
                </span>
            </td></tr>
            <tr><td style="padding-top: 1em;">
                <span class="aide" title="<b>ICRA 2022</b><br>An in-depth experimental study of sensor usage and visual reasoning of robots navigating in real environments<br>Work by Assem Sadek, Guillaume Bono, Boris Chidlovskii and Christian Wolf<br><br><br><img width=100% src=graphics/icra2022assem_big.jpg>">
                    <img src="graphics/icra2022assem.jpg">
                </span>
            </td></tr>            
            <tr><td style="padding-top: 1em;">
                <span class="aide" title="<b>NeurIPS 2021</b><br>Supervising the Transfer of Reasoning Patterns in VQA<br>Work by Corentin Kervadec, Christian Wolf, Grigory Antipov, Moez Baccouche and Madiha Nadri<br><br><br><img width=100% src=graphics/neurips2021_big.jpg>">
                    <img src="graphics/neurips2021.jpg">
                </span>
            </td></tr>
            <tr><td style="padding-top: 1em;">
                <span class="aide" title="<b>CDC 2021</b><br>Deep KKL: Data-driven Output Prediction for Non-Linear Systems<br>Work by Steeven Janny, Vincent Andrieu, Madiha Nadri and Christian Wolf<br><br>(Animation by Steeven Janny)<br><img width=100% src=graphics/cdc2021_big.jpg>">
                    <img src="graphics/animated_kkl.gif">
                </span>
            </td></tr>
            <tr><td style="padding-top: 1em;">
                <span class="aide" title="<b>IEEE Transactions on Visualization and Computer Graphics (Proceedings of VIS 2021)</b></br>VisQA: X-raying Vision and Language Reasoning in Transformers<br>Work by Théo Jaunet, Corentin Kervadec, Grigory Antipov, Moez Baccouche, Romain Vuillemot and Christian Wolf<br><br><img width=100% src=graphics/vis2021_big.jpg>">
                    <img src="graphics/animated_vis2021.gif">
                </span>
            </td></tr>
        	<tr><td style="padding-top: 1em;">
                <span class="aide" title="<b>CVPR 2021</b></br>How transferrable are reasoning patterns in VQA?<br>Work by Corentin Kervadec, Théo Jaunet, Grigory Antipov, Moez Baccouche, Romain Vuillemot and Christian Wolf<br><br><img width=100% src=graphics/cvpr2021reasoning_big.jpg>">
                    <img src="graphics/cvpr2021reasoning.png">
                </span>
            </td></tr>
        	<tr><td style="padding-top: 1em;">
                <span class="aide" title="<b>CVPR 2021</b></br>Roses Are Red, Violets Are Blue... but Should VQA Expect Them To?<br>Work by Corentin Kervadec, Grigory Antipov, Moez Baccouche, and Christian Wolf<br>https://arxiv.org/abs/2006.05121<br><br><img width=100% src=graphics/cvpr2021roses_big.jpg>">
                    <img src="graphics/cvpr2021roses.jpg">
                </span>
            </td></tr>
            <tr><td style="padding-top: 1em;">
                <span class="aide" title="<b>CVPR 2021 (oral)</b></br>SSTVOS: Sparse Spatiotemporal Transformers for Video Object Segmentation<br>Work by Brendan Duke, Abdalla Ahmed, Christian Wolf, Parham Aarabi and Graham W. Taylor<br>https://arxiv.org/abs/2101.08833<br><br><img width=100% src=graphics/cvpr2021sstvos_big.jpg>">
                    <img src="graphics/cvpr2021sstvos.png">
                </span>
            </td></tr>
			<tr><td style="padding-top: 1em;">
                <span class="aide" title="<b>ECCV 2020 (spotlight)</b><br>Learning to plan with uncertain topological maps<br>Work by Edward Beeching, Jilles Dibangoye, Olivier Simonin and Christian Wolf<br><br><br><img width=100% src=graphics/topomap_big.jpg>">
                    <img src="graphics/animated_eccv2020.gif">
                </span>
            </td></tr>
			<tr><td style="padding-top: 1em;">
                <span class="aide" title="<b>ECML-PKDD 2020</b><br>EgoMap: Projective mapping and structured egocentric memory for Deep RL<br>Work of Edward Beeching, Jilles Dibangoye, Olivier Simonin and Christian Wolf<br>https://arxiv.org/abs/2002.02286<br><br><img width=100% src=graphics/egomap_big.jpg>">
                    <img class="coucou" src="graphics/egomap_small.png">
                </span>
            </td></tr>            
            <tr><td style="padding-top: 1em;">
                <span class="aide" title="Blog post:<br>What is translation equivariance, and why do we use convolutions to get it?<br><br><img width=100% src=graphics/animated_equivariancebig.gif>">
                    <img src="graphics/animated_equivariance200.gif">
                </span>
            </td></tr>          
            <tr><td style="padding-top: 1em;">
                <span class="aide" title="<b>ICLR 2020 (spotlight)</b><br>COPHY: Counterfactual Learning of Physical Dynamics<br>Work by Fabien Baradel, Natalia Neverova, Julien Mille, Grego Mori and Christian Wolf<br>https://arxiv.org/abs/1909.12000<br><br><img width=100% src=graphics/cophy_big.jpg>">
                    <img src="graphics/animated_cophy.gif">
                </span>
            </td></tr>            
            <tr><td style="padding-top: 1em;">
                <span class="aide" title="<b>ECCV 2018</b><br>Object Level Visual Reasoning in Videos<br>Work of Fabien Baradel, Natalia Neverova, Christian Wolf, Julien Mille and Greg Mori<br>https://arxiv.org/abs/1806.06157<br><br><img width=100% src=graphics/objectlevel_big.jpg>">
                    <img src="graphics/objectlevel2.jpg">
                </span>
            </td></tr>
            <tr><td style="padding-top: 1em;">
                <span class="aide" title="<b>CVPR 2018</b><br>Glimpse Clouds: Human Activity Recognition from Unstructured Feature Points<br>Fabien Baradel, Christian Wolf, Julien Mille and Graham W. Taylor<br>https://arxiv.org/abs/1802.07898<br><br><img width=100% src=graphics/glimpse_big.jpg>">
                    <img src="graphics/animated_cvpr2018.gif">
                </span>
            </td></tr>            
            <tr><td style="padding-top: 1em;">
                <span class="aide" title="<b>BMVC 2018</b><br>Human Activity Recognition by attending to RGB frames from deep pose features<br>Fabien Baradel, Christian Wolf and Julien Mille<br>https://arxiv.org/abs/1703.10106<br><br><img width=100% src=graphics/bmvc2018_big.jpg>">
                    <img src="graphics/animated_handattention.gif">
                </span>
            </td></tr>        
			<tr><td style="padding-top: 1em;">
				<span class="aide" title="<b>CVIU 2017</b><br>Hand Pose Estimation through Weakly-Supervised Learning of a Rich Intermediate Representation<br>Natalia Neverova, Christian Wolf, Florian Nebout and Graham W. Taylor<br>arxiv.org:1511.06728<br><br><img width=100% src=graphics/cviu2017_big.jpg>">
						<img src="graphics/animated_handposejoints.gif">
				</span>
			</td></tr>            
			<tr><td style="padding-top: 1em;">
				<span class="aide" title="<b>IEEE Access 2016</b><br>Learning human identity from motion pattern<br>Natalia Neverova, Christian Wolf, Griffin Lacey, Lex Fridman, Deepak Chandra, Brandon Barbello and Graham W. Taylor<br>arxiv:1511.03908)<br><br><img width=100% src=graphics/access2016_big.jpg>">
						<img src="graphics/teaser_atap2016.jpg">
				</span>
			</td></tr>
			<tr><td>
				<span class="aide" title="<b>IEEE PAMI 2016</b><br>Moddrop: Multimodal Gesture Recognition<br>Ranked 1st at the ChaLearn 2014 Competition<br>Natalia Neverova, Christian Wolf, Graham W. Taylor and Florian Nebout<br><br><img width=100% src=graphics/pami2016_big.jpg>">
					<img src="graphics/animated_gestes1.gif">
				</span>
			</td></tr>
			
		</table>
	</div>

	<div class="portrait-right">

        <img style="max-width: 100%; max-height: 110vh; height: auto; width: auto\9;" src="miscphotos/banner2023.jpg">


		<div class="navmenunew" style="text-align:  left; max-width: 100%;">
	   <ul>		
		<li class="first"><a href="publications/index_bydate.html">Publications</a></li>
		<li> <a href="publications/pres.html">Talks</a></li>		
	   </ul>
    </div>
    


        <p>
		<span style="color: black; font-weight:bold; font-size: larger;">Christian WOLF</span>
		is Principal Scientist at <a href="https://europe.naverlabs.com">Naver Labs Europe</a>, where he leads the <em>Spatial AI</em> team.
        He is interested in AI for Robotics, in particular machine learning and embodied computer vision; large-scale learning of the capacity to perform high-level reasoning from visual observations, and more recently the connections between machine learning and control.
       	He is a member of the directing committee of <a href="http://www.gdr-isis.fr/">GDR ISIS</a> and co-leader of it's topic "<em>Machine Learning</em>".
        He has supervised <a href="#phdstudents">16 defended PhD theses</a>, is an associate editor of <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE-Transactions on PAMI</a> and area chair of  NeurIPS (<a href="https://nips.cc/Conferences/2020">2020</a>, <a href="https://nips.cc/Conferences/2021">2021</a>, <a href="https://neurips.cc">2023</a>), ICLR (<a href="https://iclr.cc/Conferences/2021">2021</a>, <a href="https://iclr.cc/Conferences/2023">2023</a>, <a href="https://iclr.cc/">2024</a>), ICML (<a href="https://icml.cc/Conferences/2021">2021</a>, <a href="https://icml.cc/Conferences/2022">2022</a>), CVPR (<a href="http://cvpr2020.thecvf.com/">2020</a>), ICCV (<a href="http://iccv2021.thecvf.com/home">2021</a>, <a href="https://iccv2023.thecvf.com/">2023</a>) and
        ECCV (<a href="https://eccv2022.ecva.net/">2022</a>, <a href="https://eccv2024.ecva.net/">2024</a>).
		</p>

		From 2005 to 2021 he was associate professor (Maître de Conférences, HDR)
		at <a href="http://www.insa-lyon.fr">INSA de Lyon</a> and <a href="http://liris.cnrs.fr">LIRIS</a>, a CNRS laboratory, where he was also  the head of the <a href="https://chriswolfvision.github.io/remember">AI chair / chair in Artificial Intelligence</a> (<a href="formergroup.html">the group</a>).
		He received his MSc in computer science from
				<a href="http://www.tuwien.ac.at">TU Vienna</a>, Austria,
				in 2000, and a PhD in computer science from
				<a href="http://www.insa-lyon.fr">INSA de Lyon</a>,
				France, in 2003. In 2012 he obtained the habilitation diploma, also from
				<a href="http://www.insa-lyon.fr">INSA de Lyon</a>.
            			
        In the past he was also member of the scientific committee of <a href="https://www.gdria.fr/">GDR IA</a>; member of the board of AI experts at the French national supercomputing cluster <a href="https://www.genci.fr">GENCI</a>, and member of evaluation <a href="https://anr.fr">ANR</a> committee "<em>Artificial Intelligence</em>" from 2019-2021 and <a href="https://anr.fr">ANR</a> committee "<em>Interaction and Robotics</em>" from 2016-2018.
        </p>
		</td>
		</tr>
		

		Twitter: <a href="https://twitter.com/chriswolfvision">@chriswolfvision</a><br>
		Blog/Medium: <a href="https://medium.com/@chriswolfvision">@chriswolfvision</a>

		<br>
		<br>
	
		<h3>Recent news ( <a href="publications/index.html">All publications</a> | <a href="http://scholar.google.com/citations?user=idYS1AIAAAAJ&hl=en">Google citations page</a> )</h3>
		<ul class="sparselist" style="margin-bottom: 0.5ex">			
			<li> 10.01.2022: I joined <a href="https://europe.naverlabs.com">Naver Labs Europe</a> as Principal Scientist!</li>
			<li> 25.11.2020: I am <b>outstanding BMVC 2021</b> <a href="https://twitter.com/BMVCconf/status/1463481756586283013?s=20">reviewer</a>.</li>
			<li>20.06.2021: My student <a href="https://scholar.google.com/citations?user=NAI5mi4AAAAJ&hl=fr">Pierre Marza</a> won the <a href="http://multion-challenge.cs.sfu.ca/">Multi Object Navigation Challenge</a> at CVPR 2021! <a href="https://arxiv.org/abs/2107.06011">[arxiv]</a>.</li>		
			<li> 19.05.2021: I am <b>outstanding CVPR 2021</b> <a href="http://cvpr2021.thecvf.com/node/184">reviewer</a>.</li>			
			<li>07.04.2021: <a href="https://fabienbaradel.github.io/">Fabien Baradel</a>, former PhD student at our group, received the runner-up (2nd place) thesis prize  by <a href="http://afrif.irisa.fr">AFRIF</a> (French association of pattern recognition). Congrats! <a href="http://www.afrif.asso.fr/?p=737">[Prize-page]</a>.</li>						
			<li> 28.08.2020: I am <b>outstanding BMVC 2020</b> <a href="https://bmvc2020.github.io/people/reviewers/">reviewer</a>.</li>
			<li>12.12.2019: My <b>AI Chair position</b> has been accepted, titled: <a href="https://chriswolfvision.github.io/remember/">"REMEMBER - Learning Reasoning, Memory and Behavior"</a>, which will provide funding for the next years of our research! The chair is co-financed by ANR, Naver Labs Europe and INSA-Lyon. Team members are  <a href="http://perso.citi-lab.fr/osimonin/">Olivier Simonin</a>, <a href="http://perso.citi-lab.fr/jdibangoy/">Jilles Dibangoye</a>, <a href="https://perso.liris.cnrs.fr/laetitia.matignon/">Laetitia Matignon</a> and <a href="https://europe.naverlabs.com/people_user/Boris-Chidlovskii/">Boris Chidlovskii</a>.</li>
			<li>26.11.2019: I joined <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE-Transactions on PAMI</a> as an <b>Associate Editor</b>.</li>
			<li>12.07.2019: <b>ANR grant</b> "<a href="https://projet.liris.cnrs.fr/delicio/">Delicio</a>" accepted, addressing stable and robust control in complex environments combining machine learning and control theory. Partners:
				<ul style="list-style-type: square;">
                    <li> LIRIS/INSA-Lyon (<a href="index.html">Christian Wolf</a> (Project Leader), <a href="https://perso.liris.cnrs.fr/laetitia.matignon/">Laetitia Matignon</a>) </li>
                    <li> CITI/INSA-Lyon (<a href="http://perso.citi-lab.fr/jdibangoy/#/">Jilles Dibangoye</a>, <a href="http://perso.citi-lab.fr/osimonin/">Olivier Simonin</a>, <a href="https://ievred.github.io/">Ievgen Redko</a> (LHC Laboratory)) </li>
                    <li> LAGEPP/Lyon 1 University (<a href="https://madihanadri.github.io/">Madiha Nadri</a>, <a href="https://sites.google.com/site/vincentandrieu/">Vincent Andrieu</a>, <a href="https://sites.google.com/site/astolfidaniele/">Daniele Astolfi</a> <a href="https://www.ec-lyon.fr/contacts/laurent-bako">Laurent Bako</a>(AMPERE Laboratory), <a href="https://www.ec-lyon.fr/contacts/giacomo-casadei">Giacomo Casadei</a>(AMPERE Laboratory)) </li>
                    <li> Onera (<a href="https://www.onera.fr/en/staff/sylvain-bertrand">Sylvain Bertrand</a>, <a href="http://julien.marzat.free.fr/">Julien Marzat</a>, <a href="https://scholar.google.com/citations?user=xg8ezOQAAAAJ&hl=en">Hélène Piet-Lahanier</a>) </li>
                </ul>
			</li>
			<li> 29.05.2019: I am <b>outstanding CVPR 2019</b> <a href="http://cvpr2019.thecvf.com/files/CVPR_2019_Program_Guide.pdf">reviewer</a>.</li>			
      		<li>10.09.2018: We released <a href="https://fabienbaradel.github.io/masks_data">complementary mask prediction</a> on VLOG and EPIC KITCHEN datasets (saves ~2 months of calculation on a single GPU).</li>
			<li>
                16.05.2017: My former PhD student <a href="https://nneverova.github.io/">Natalia Neverova</a>
                won the 2017 French PhD thesis prize of Club EEA/GDR ISIS for work on Deep Learning of Human Motion. Congratulations!
            </li>
            <li> 01.05.2016: I am <b>outstanding CVPR 2016</b> <a href="http://cvpr2016.thecvf.com/">reviewer</a>.</li>
			<li> 12.02.2016: French-Canadian <a href="https://projet.liris.cnrs.fr/deepvis/">ANR/NSERC project "Deepvision"</a> has been accepted. It involves 4 partners: LIRIS/INSA-Lyon, LIP6/UPMC, University of Guelph, Simon Fraser University.</li>
			<li>
				16.06.2015: Winners of the CVPR 2015 - OpenCV Vision Challenge (<a href="http://code.opencv.org/projects/opencv/wiki/VisionChallenge">First in category "gesture recognition"</a>)
			</li>
			<li>
				09.06.2014: Winners of the ECCV 2014 - Chalearn competition: work of <a href="https://nneverova.github.io/">Natalia Neverova</a> on gesture recognition (<a href="http://gesture.chalearn.org/challenge-results">Results</a>; More in the <a href="papers/pami2015.pdf">PAMI paper</a>).</td></tr>
			</li>			
		</ul>

        <h3>Recent PhD committees</h3>
        <ul class="sparselist">
            <li>64. (16.01.2024) <a href="https://steevenjanny.github.io/">Steeven Janny</a> (supervised), Université de Lyon, <i>"Identification and Simulation of Physical Systems with structured Deep Learning and Inductive Knowledge"</i>.</li>
            <li>63. (20.10.2023) <a href="">Antoine Plumerault</a>, Centrale Supelec, Paris Saclay, <i>"Controlling image generative models without supervision"</i>.</li>
            <li>62. (11.10.2023) <a href="https://alexrame.github.io/">Alexandre Ramé</a>, Sorbonne University, Paris, <i>"Diverse and Efficient Ensembling of Deep Networks"</i>.</li>
            <li>61. (19.09.2023) <a href="https://scholar.google.fr/citations?user=mLytdOoAAAAJ&hl=en">Yuming Du</a>, ENPS, Paris, <i>"Enhancing Human-Robot Interaction with Computer Vision"</i>.</li>
            <li>60. (06.09.2023) <a href="https://scholar.google.com/citations?user=ejHZv20AAAAJ&hl=en">Elliot Chane-Shane</a>, PSL University, Inria Paris, <i>"Learning Multi-Task Policies for Robotics"</i>.</li>
            <li>59. (28.06.2023) <a href="https://yuan-yin.github.io">Yuan Yin</a>, Sorbonne University, <i>"Physics-Aware Deep Learning and Dynamical Systems: Hybrid Modeling and Generalization"</i>.</li>
            <li>58. (04.04.2023) <a href="https://scholar.google.com/citations?user=mkdVWLwAAAAJ&hl=en">Pierre-Louis Guhur</a>, Inria, Université Paris Sciences et Lettres, <i>"Language-guided navigation and manipulation in robotics using
transformers"</i>.</li>
            <li>57. (31.03.2023) <a href="https://cdancette.fr/">Corentin Dancette</a>, Sorbonne University, , <i>"Language-guided navigation and manipulation in robotics using
transformers"</i>.</li>
            <li>56. (20.12.2022) <a href="">Samuel Felton</a>, Inria, Unversity de Rennes, <i>"Deep latent representations for visual servoing"</i>.</li>
            <li>55. (21.11.2022) <a href="https://scholar.google.com/citations?user=3QSALjX498QC&hl=fr">Zongwei Wu</a>, Unversity of Bourgogne, <i>"Depth Attention for Scene Understanding"</i>.</li>
            <li>54. (22.09.2022) <a href="https://scholar.google.com/citations?user=9ehNv-4AAAAJ&hl=fr">Aloïs Pourchot</a>, Sorbonne Unversity, <i>"Improving Radiographic Diagnosis with Deep Learning in Clinical Settings"</i>.</li>            
            <li>53. (16.05.2022) <a href="https://theo-jaunet.github.io/">Théo Jaunet</a> (supervised), Université de Lyon, <i>"Deep learning interpretability with visual analytics: Exploring reasoning and bias exploitation"</i>.</li>            
            <li>52. (03.05.2022) <a href="https://edbeeching.github.io/">Edward Beeching</a> (supervised), Université de Lyon, <i>"Large-scale automatic learning of autonomous agent behavior with structured deep reinforcement learning"</i>.</li>                        
            <li>(...) <a href="research/jurys.html">[All committees]</a>)</li>            
        </ul>

		<h3>In the press:</h3>
		<ul class="sparselist">
			<li>23.09.2020: in "Libération" on Twitters biased image cropping algorithm <a href="https://www.liberation.fr/checknews/2020/09/22/l-algorithme-de-twitter-choisit-il-toujours-une-personne-blanche-dans-ses-apercus-d-image_1800209">[Web]</a>
			<li>01.11.2019: In "Usine nouvelle" on Deepmind's Starcraft algorithm <a href="https://www.usinenouvelle.com/editorial/comment-deepmind-est-devenu-l-un-des-meilleurs-joueurs-de-starcraft-ii.N899894">[Web]</a>
			<li>19.06.2018: Student Fabien Baradel is interviewed for the "CVPR Daily" online journal <a href="https://www.rsipvision.com/CVPR2018-Tuesday/14">[Web]</a><a href="inthepress/cvpr2018daily.pdf">[PDF]</a>.</li>
			<li>05.04.2016: In the CNRS journal on automatic authentification of smartphone users with Deep Learning
				<a href="inthepress/press-cnrsjournal-160901.pdf">[PDF]</a>
				<a href="https://lejournal.cnrs.fr/articles/bouger-pour-sidentifier">[web-version]</a>
				<a href="https://news.cnrs.fr/articles/biometrics-identification-in-action">[english-version]</a>
			</li>
			<li>11.03.2016: In "Industrie & Technologies" on AI and Deep Learning <a href="http://www.industrie-techno.com/les-retombees-industrielles-de-l-intelligence-artificielle.43218">[direct link]</a></li>
			<li>25.07.2015: In "Le monde" on Deep Learning <a href="http://www.lemonde.fr/pixels/article/2015/07/24/comment-le-deep-learning-revolutionne-l-intelligence-artificielle_4695929_4408996.html">[direct link]</a><a href="papers/press-lemonde-2015.pdf">[saved-pdf]</a></li>
			<li>28.04.2011: In "Usine Nouvelle" on Kinect <a href="inthepress/usinenouvelle20110428.pdf">[pdf]</a></li>
			<li>28.01.2011: In "Millenaire 3" on robotics <a href="papers/interview_millenaire3_2011.pdf">[pdf]</a></li>
			<li>10.03.2010: In "Le monde" on video surveillance <a href="inthepress/lemonde20120310.pdf">[pdf]</a></li>
		</ul>

    <h3>Current PhD students (2)</h3>
    <a id="phdstudents"></a>
    <div style="margin-left: 1em;">

		
		<ul class="sparselist">
			<li><a href="https://scholar.google.com/citations?user=NAI5mi4AAAAJ&hl=fr">Pierre Marza</a> (11/2020-);  (co-supervised with <a href="https://perso.liris.cnrs.fr/laetitia.matignon/">Laetitia Matignon</a> (LIRIS); <a href="http://perso.citi-lab.fr/osimonin/">Olivier Simonin</a>  ( <em>INRIA/CITI/INSA-Lyon</em>)).</li>			
			<li><a href="https://www.assemsadek.com">Assem Sadek</a> (06/2020-01/2024); Building Autonomous Agents with Hybrid Navigation Policies (co-supervised with <a href="https://europe.naverlabs.com/people_user/Boris-Chidlovskii">Boris Chidlovskii</a> (<em>Naver Labs Europe) and <a href="https://perso.liris.cnrs.fr/atilla.baskurt/wiki/doku.php">Atilla Baskurt</a> (LIRIS, INSA-Lyon))</em>.</li>
            <!--
			<li><a href="https://fr.linkedin.com/in/quentin-possama%C3%AF-425420142">Quentin Possamaï</a> (01/2020-);  Stable and robust control with AI and control-theory (co-supervised with <a href="https://scholar.google.com/citations?user=KOXeslUAAAAJ&hl=en">Madiha Nadri</a> (<em>LAGEPP/Univ Lyon 1)</em> and <a href="https://sites.google.com/site/laurentbako">Laurent Bako</a> (<em>AMPERE / Ecole Centrale de Lyon</em>).</li>      		
            -->
    	</ul>
		
  </div>

    <h3>Former PhD students (16)</h3>
    <div style="margin-left: 1em;">

    <ul class="sparselist">
            <li><a href="https://steevenjanny.github.io/">Dr. Steeven Janny</a> (09/2020-01/2024);  Identification and Simulation of Physical Systems with structured Deep Learning and Inductive Knowledge" (co-supervised with <a href="https://madihanadri.github.io/">Madiha Nadri</a> (<em>LAGEPP/Univ Lyon 1</em>) and <a href="https://perso.liris.cnrs.fr/julie.digne/">Julie Digne</a> (<em>LIRIS/CNRS</em>)), current position: senior data scientist at Alstom.</li>
            <li><a href="https://theo-jaunet.github.io/">Dr. Théo Jaunet</a> (10/2018-05/2022);  Transparency and Explainability of Machine Learning (co-supervised with <a href="https://romain.vuillemot.net/">Romain Vuillemot</a> (<em>LIRIS/Ecole Centrale de Lyon</em>)).</li>                       
    		<li><a href="https://edbeeching.github.io">Dr. Edward Beeching</a> (10/2018-05/2022);  Large-scale automatic learning of autonomous agent behavior with structured deep reinforcement learning (co-supervised with <a href="http://perso.citi-lab.fr/osimonin/">Olivier Simonin</a> and <a href="http://perso.citi-lab.fr/jdibangoy/#/">Jilles Dibangoye</a> (both <em>INRIA/CITI/INSA-Lyon</em>))current position: researcher at Hugging Face.</li>
            <li><a href="https://corentinkervadec.github.io">Dr. Corentin Kervadec</a> (10/2018-12/2021);  Vision and Language for Scene Comprehension (co-supervised with <a href="https://scholar.google.fr/citations?user=olfpe-kAAAAJ&hl=en">Moez Baccouche</a> and <a href="https://scholar.google.com/citations?user=CoOz8K0AAAAJ&hl=en">Grigory Antipov</a> (both <em>Orange Labs R&D</em>)).</li>
    		<li><a href="https://fabienbaradel.github.io">Dr. Fabien Baradel</a> (10/2016-06/2020); Structured Deep Learning for Video Analysis (co-supervised with <a href="http://www.rfai.li.univ-tours.fr/PagesPerso/jmille/">Julien Mille</a> (<em>LI/INSA Val de Loire</em>)); <a href="papers/phdthesis-baradel2020.pdf">[pdf-thesis]</a><a href="http://www.afrif.asso.fr/?p=737">[thesis-prize]</a>; Current position: research scientist at Naver Labs Europe.</li>
			<li><a href="https://perso.liris.cnrs.fr/quentin.debard">Dr. Quentin Debard</a> (12/2016-05/2020); Learning to collaboratively interact with big touch tables  (co-supervised with <a href="http://asi.insa-rouen.fr/enseignants/~scanu/">Stéphane Canu</a> (<em>LITIS/INSA Rouen</em>)).</li>
			<li><a href="https://liris.cnrs.fr/membres?idn=bmoysset">Dr. Bastien Moysset</a> (10/2014-05/2018); Document analysis by deep learning (co-supervised with <a href="https://www.linkedin.com/in/christopher-kermorvant-87158b2">Christopher Kermorvant</a> (<em><a href="http://www.a2ia.com/en">A2IA</a>/<a href="http://www.teklia.com">Teklia</a></em>)); <a href="papers/phdthesis-moysset2018.pdf">[pdf-thesis]</a>.</li>

			<li><a href="http://liris.cnrs.fr/membres?idn=dfourure">Dr. Damien Fourure</a> (10/2014-12/2017); Learning deep representations of videos (co-supervised with <a href="http://portail.univ-st-etienne.fr/bienvenue/utilitaires/m-tremeau-alain-1543.kjsp">Alain Tremeau</a>, <a href="http://home.heeere.com/">Rémi Emonet</a>, <a href="http://perso.univ-st-etienne.fr/frel9915/">Elisa Fromont</a>, <a href="http://perso.univ-st-etienne.fr/muda8804/">Damien Muselet</a> (all <em>LHC,Saint-Etienne</em>)); <a href="papers/phdthesis-fourure2017.pdf">[pdf-thesis]</a>.</li>

            <li><a href="https://liris.cnrs.fr/membres?idn=edogan">Dr. Emre Dogan</a> (01/2013-07/2017); Joint recognition of human activities by multiple robots (co-supervised with <a href="http://liris.cnrs.fr/atilla.baskurt">Atilla Baskurt</a> (<em>LIRIS/INSA-Lyon</em>) and <a href="http://www.goneneren.com/">Gönen Eren</a> (<em>Galatasaray University, Istanbul</em>)); <a href="papers/phdthesis-dogan2017.pdf">[pdf-thesis]</a></li>

			<li><a href="https://nneverova.github.io/">Dr. Natalia Neverova</a> (10/2012-04/2016); Deep Learning for Human Motion Analysis (co-supervised with <a href="http://www.uoguelph.ca/~gwtaylor/">Graham W. Taylor</a> (<em> University of Guelph, Canada</em>)); <a href="papers/phdthesis-neverova2016.pdf">[pdf-thesis]</a>; [<a href="http://www.gdr-isis.fr/news/4602/121/Prix-de-these-ISIS-GRETSI-Club-EEA.html">thesis prize</a>]; current position: research lead at <a href="https://research.facebook.com/ai/">Facebook AI Research</a>.</li>
			<li><a href="http://www.gipsa-lab.grenoble-inp.fr/page_pro.php?vid=1752">Dr. Alaeddine Mihoub</a> (1.10.2012-8.10.2015); Attention et communication homme-robot dans des tâches de co-manipulation
 (co-supervised with <a href="https://www.gipsa-lab.grenoble-inp.fr/~gerard.bailly/">Gerard Bailly</a> (<em>Gipsalab, Grenoble</em>)); <a href="papers/phdthesis-mihoub2015.pdf">[pdf-thesis]</a>; current position: assistant professor - college of business and economics at Qassim University.</li>
		    <li><a href="http://liris.cnrs.fr/membres?idn=mjiu">Dr. Jiu Mingyuan</a> (01.10.2010-03.04.2014); Spatial information and end-to-end training for visual recognition (co-supervised with <a href="http://liris.cnrs.fr/atilla.baskurt">Atilla Baskurt</a> (<em>LIRIS/INSA-Lyon</em>)); <a href="http://liris.cnrs.fr/Documents/Liris-7054.pdf">[pdf-thesis]</a>; current position: assistant professor at Zhengzhou University.</li>
			<li><a href="http://www.busim.ee.boun.edu.tr/~oya/">Dr. Oya Celiktutan</a> (01.01.2011-06.09.2013); Action recognition in videos (co-supervised with <a href="http://www.ee.boun.edu.tr/busim/B%C3%BClentSankur/tabid/956/language/en-US/Default.aspx">Bülent Sankur</a> (<em>Bogazici University, Istanbul</em>)); current position: lecturer in engineering (robotics), Kings College, London, UK.</li>
			<li><a href="https://scholar.google.com/citations?user=olfpe-kAAAAJ&hl=en">Dr. Moez Baccouche</a> (01.10.2009-15.07.2012);
			Video indexation taking into account human behavior (co-supervised with Frank Mamalet (<em>Orange Labs</em>), Christophe Garcia and <a href="http://liris.cnrs.fr/atilla.baskurt">Atilla Baskurt</a> (both </em>LIRIS/INSA-Lyon</em>)); <a href="http://liris.cnrs.fr/Documents/Liris-6240.pdf">[pdf-thesis]</a>; current position: researcher at Orange Labs R&D.</li>
			<li><a href="http://liris.cnrs.fr/vincent.vidal">Dr. Vincent Vidal</a> (01.10.2008-09.12.2011); Remeshing and mesh simplification with probabilistic graphical models (co-supervised with Florent Dupont (<em>LIRIS/University Lyon 1</em>)); current position: assistant professor (MCF) at LIRIS laboratory; <a href="http://liris.cnrs.fr/Documents/Liris-5345.pdf">[pdf-thesis]</a></li>
			<li><a href="http://liris.cnrs.fr/anh-phuong.ta">Dr. Anh-Phuong TA</a> (01.02.2008-26.11.2010);
			Inexact graph matching and it's application to objet detection and action recognition (co-supervised with <a href="http://liris.cnrs.fr/guillaume.lavoue/">Guillaume Lavoué</a> and <a href="http://liris.cnrs.fr/atilla.baskurt">Atilla Baskurt</a> (both <em>LIRIS/INSA-Lyon</em>)); <a href="papers/phdthesis-ta2010.pdf">[pdf-thesis]</a></li>
		</ul>		
		<!--
		<h4>Contractual researcher</h4>
    <ul class="sparselist">
        <li><a href="">Tom Gillooly</a> (12/2018-); Learning Robot navigation through language (co-supervised with <a href="http://www.rfai.li.univ-tours.fr/PagesPerso/jmille/">Julien Mille</a> and <a href="https://thoth.inrialpes.fr/~schmid/">Cordelia Schmid</a>).</li>
    </ul>

    <h4>Former post-doctoral Students</h4>
  		<ul class="sparselist">
			<li><a href="https://sites.google.com/site/drkhanrizwan17/">Dr. Rizwan Khan</a></span> (12/2013-11/2014); Semantic labelling of HD videos taken from occulometric eye-glasses
			(co-supervised with <a href="http://www.rfai.li.univ-tours.fr/PagesPerso/jmille/">Julien Mille</a>)</li>
		</ul>
	-->
  </div>

	
		<h3>Former research projects</h3>
		<ul class="sparselist">		
            <li>
                Bevor leaving to Naver Labs Europe, I held the AI Chair in research and teaching <a href="https://chriswolfvision.github.io/remember/">"REMEMBER - Learning Reasoning, Memory and Behavior"</a> at INSA-Lyon, co-financed by ANR, Naver Labs Europe and INSA-Lyon. Team members are  <a href="http://perso.citi-lab.fr/osimonin/">Olivier Simonin</a>, <a href="http://perso.citi-lab.fr/jdibangoy/">Jilles Dibangoye</a>, <a href="https://perso.liris.cnrs.fr/laetitia.matignon/">Laetitia Matignon</a> and <a href="https://europe.naverlabs.com/people_user/Boris-Chidlovskii/">Boris Chidlovskii</a>.
            </li>           
				I was the project leader of ANR project "DeLiCo"</a> (stable and robust control in complex environments combining machine learning and control theory), involving 4 partners:
                <ul style="list-style-type: square;">
                    <li> LIRIS/INSA-Lyon (<a href="index.html">Christian Wolf</a>, <a href="https://perso.liris.cnrs.fr/laetitia.matignon/">Laetitia Matignon</a>) </li>
                    <li> CITI/INSA-Lyon (<a href="http://perso.citi-lab.fr/jdibangoy/#/">Jilles Dibangoye</a>, <a href="http://perso.citi-lab.fr/osimonin/">Olivier Simonin</a>, <a href="https://ievred.github.io/">Ievgen Redko</a> (LHC Laboratory)) </li>
                    <li> LAGEPP/Lyon 1 University (<a href="https://madihanadri.github.io/">Madiha Nadri</a>, <a href="https://sites.google.com/site/vincentandrieu/">Vincent Andrieu</a>, <a href="https://sites.google.com/site/astolfidaniele/">Daniele Astolfi</a> <a href="https://www.ec-lyon.fr/contacts/laurent-bako">Laurent Bako</a>(AMPERE Laboratory), <a href="https://www.ec-lyon.fr/contacts/giacomo-casadei">Giacomo Casadei</a>(AMPERE Laboratory)) </li>
                    <li> Onera (<a href="https://www.onera.fr/en/staff/sylvain-bertrand">Sylvain Bertrand</a>, <a href="http://julien.marzat.free.fr/">Julien Marzat</a>, <a href="https://scholar.google.com/citations?user=xg8ezOQAAAAJ&hl=en">Hélène Piet-Lahanier</a>) </li>
                </ul>
            </li>
		<li>
				I was the French leader for French-Canadian <a href="https://projet.liris.cnrs.fr/deepvis/">ANR/NSERC project "Deepvision"</a>, involving 4 partners:
                <ul style="list-style-type: square;">
                    <li> LIRIS/INSA-Lyon (<a href="index.html">Christian Wolf</a> - French Leader; <a href="http://www.rfai.li.univ-tours.fr/PagesPerso/jmille//">Julien Mille</a>) </li>
                    <li> LIP6/UPMC (<a href="http://webia.lip6.fr/~cord">Matthieu Cord</a>, <a href="http://webia.lip6.fr/~thomen/">Nicolas Thome</a>) </li>
                    <li> University of Guelph (<a href="http://www.uoguelph.ca/~gwtaylor/">Graham W. Taylor</a>; Canadian leader)</li>
                    <li> Simon Fraser University (<a href="http://www.cs.sfu.ca/~mori/">Greg Mori</a>) </li>
                </ul>
            </li>
      	<li>
				<a href="https://solstice.univ-st-etienne.fr/">ANR blanc "Solstice"</a>; graphes and structured models for computer vision (2014 - 2018).
			</li>
            <li>
                <a href="http://www.minalogic.com/TPL_CODE/TPL_PROJET/PAR_TPL_IDENTIFIANT/3276/15-annuaire-innovations-technologiques-nanotechnologie-systeme-embarque.htm#.VUhr7Gb8-n8">Investissements d'Avenir: "INTERABOT"</a>; gesture and object recognition in mobile robotics environment (5/2012-5/2016; leader of "INSA" partner).
            </li>
			<li>
				<a href="http://imu.universite-lyon.fr/bilan-appels-internes-de-recherche-2013/projet-riviere-209479.kjsp">Labex IMU "RIVIERE"</a>; semantic labeling of HD videos acquire from portable eyetracking glasses  (2013 - 2015).
			</li>
			<li>
				BQR INSA "CROME"; Multi-view multi-robot scene understanding and fleet coordination (2014 - 2016).
			</li>
			<li>
				<a href="">ANR Canada</a> (2007-2010) - Comportements Anormaux : Analyse, Détection, Alerte; ; leader of "INSA" partner.
			</li>
			<li>
				<a href="http://www-rech.telecom-lille1.eu/madras">ANR Madras</a> (2008-2011) - 3D Models And Dynamic models Representation And Segmentation
			</li>
			<li>
				<a href="http://labh-curien.univ-st-etienne.fr/wiki-sattic/index.php/Main_Page">ANR Sattic</a> (2007-2011) - Strings and Trees for Thumbnail Images Classification.
			</li>
		</ul>		

		<h3>Responsibilities (National, French)</h3>
        <ul class="sparselist" style="margin-bottom: 0.5ex">
            <li>2017-now: Membre du comité de direction du <a href="http://gdr-isis.fr">GDR ISIS (Information Signal Image Vision)</a> du CNRS</li>
            <li>2016-now: Membre du comité scientifique du <a href="http://www.gdria.fr/">GDR Intelligence Artificielle</a> du CNRS</li>
            <li>2018-2022: Co-animation du GT "Apprentissage et Robotique" du <a href="https://www.gdr-robotique.org/">GDR Robotique</a> du CNRS</li>
            <li>2019/2020: Membre du comité d'évaluation CES 23 de l'ANR</a> (Intelligence artificielle)</li>
            <li>2016-2018: Membre du comité d'évaluation <a href="http://www.agence-nationale-recherche.fr/fileadmin/comites/2017/CES-aapg2017.pdf">CES 33 de l'ANR</a> (Robotique et Interactions, 2 ans)</li>
            <li>2021-now: Membre elu du conseil du <a href="http://liris.cnrs.fr/">laboratoire LIRIS</a></li>
            <li>2017-2020: Membre elu du conseil de la <a href="http://fil.cnrs.fr/">Fédération Informatique de Lyon</a></li>
            <li>2009-2017: Responsable de l'enseignement de l'informatique en deuxième année au premier cycle de l'INSA de Lyon</li>
        </ul>

        <h3>Responsibilities (International)</h3>
        <ul>
        	<li>Associate editor for <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE-Transactions on Pattern Analysis and Machine Intelligence (PAMI)</a></li>
        	<li>List of <a href="research/jurys.html">PhD and HDR defense committees</a></li>
        </ul>

    		<h3>Recent committee participations (area chair, reviewer)</h3>
    		<ul class="sparselist" style="margin-bottom: 0.5ex">   
                <li>Area char for <a href="https://iclr.cc/">ICLR 2024</a>, <a href="https://eccv2024.ecva.net/">ECCV 2024</a>.</li>
                <li>Reviewer for <a href="https://cvpr2023.thecvf.com/">CVPR 2023</a>.</li>
                <li>Area chair for <a href="https://iclr.cc/Conferences/2023">ICLR 2023</a>, <a href="https://iccv2023.thecvf.com/">ICCV 2023</a>,  <a href="https://neurips.cc">NeurIPS 2023</a>.
    			<li>Area chair for <a href="https://icml.cc/Conferences/2022">ICML 2022</a>, <a href="https://eccv2022.ecva.net/">ECCV 2022</a> .</li>
    			<li>Reviewer for <a href="https://cvpr2022.thecvf.com">CVPR 2022</a>, <a href="https://bmvc2022.org">BMVC 2022</a>.</li>
    			<li>Area chair for <a href="https://iclr.cc/Conferences/2021">ICLR 2021</a>, <a href="http://iccv2021.thecvf.com/home">ICCV 2021</a>, <a href="https://icml.cc/Conferences/2021">ICML 2021</a>, <a href="https://nips.cc/Conferences/2021">NeurIPS 2021</a>.</li>
    			<li> Reviewer for <a href="http://cvpr2021.thecvf.com">CVPR 2021 (outstanding reviewer)</a>, <a href="https://www.bmvc2021.com/">BMVC 2021 (outstanding reviewer)</a>.</li>    			
    			<li> Area chair for <a href="https://nips.cc/Conferences/2020/">NeurIPS 2020</a> and
    			<a href="http://cvpr2020.thecvf.com/">CVPR 2020</a>.</li>
    			<li> Reviewer for
                    <a href="https://openreview.net/group?id=ICLR.cc/2020/Conference">ICLR 2020</a>,                    
                    <a href="https://openreview.net/group?id=thecvf.com/ECCV/2020/Conference">ECCV 2020</a>,
                    <a href="https://bmvc2020.github.io/">BMVC 2020</a> (<a href="https://bmvc2020.github.io/people/reviewers/">outstanding reviewer</a>).
                </li>
    			<li> Area chair for FG 2019</li>
          		<li> Reviewer for
                    <a href="http://cvpr2019.thecvf.com/">CVPR 2019</a> (<a href="http://cvpr2019.thecvf.com/files/CVPR_2019_Program_Guide.pdf">outstanding reviewer</a>),
                    <a href="https://iclr.cc/Conferences/2019">ICLR 2019</a>,
                    <a href="https://icml.cc/Conferences/2019">ICML 2019</a>,
                    <a href="https://nips.cc/">NeurIPS 2019</a>,
                    <a href="https://bmvc2019.org/">BMVC 2019</a>,
                    <a href="http://www.ecmlpkdd2019.org/">ECML-PKDD 2019</a>.
          		</li>
    			<li> PC member for <a href="http://www.ijcai-18.org/">IJCAI 2018</a>,
    			<a href="https://project.inria.fr/humans2018/">CVPR 2018 Workshop on Human Pose, Motion, Activities and Shape in 3D</a>,
    			<a href="https://sites.google.com/view/hands2018/">ECCV 2018 Workshop on Hands in Action</a>,
    			<a href="https://rfiap2018.ign.fr">RFIAP 2018</a>.</li>
    			</li>
    			<li> Reviewer for
                    <a href="http://cvpr2018.thecvf.com/">CVPR 2018</a>,
                    <a href="https://nips.cc/Conferences/2018">NIPS 2018</a>,
                    <a href="http://www.iclr.cc/doku.php?id=ICLR2018:main&redirect=1">ICLR 2018</a>,
                    <a href="https://icml.cc/">ICML 2018</a>,
                    <a href="https://www.ijcai-18.org/">IJCAI 2018</a>,
                    <a href="http://bmvc2018.org/">BMVC 2018</a>
                </li>    			
    			<li>PC member of <a href="https://bmvc2017.london/">BMVC 2017</a>,
                <a href="http://icvl.ee.ic.ac.uk/hands17/dates/">ICCV 2017 Workshop on hands in action</a>,
    			<a href="http://u-pat.org/ICDAR2017/">ICDAR 2017</a>, <a href="http://www.cvl.isy.liu.se/CAIP2017.html">CAIP 2017</a> and <a href="http://caip.eu.org/caip2015">CAIP 2015</a></li>    			
    			<li> Reviewer for
                    <a href="http://cvpr2017.thecvf.com">CVPR 2017</a>,
                    <a href="http://iccv2017.thecvf.com/">ICCV 2017</a>,
                    <a href="https://nips.cc/Conferences/2016">NIPS 2017</a>,
    				<a href="http://www.iclr.cc/doku.php?id=ICLR2017:main&redirect=1">ICLR 2017</a>
                </li>
    			<li>PC member of <a href="http://www-rech.telecom-lille.fr/uha3ds2016">UHA3DS’16"</a></li>
    			<li> Reviewer for
    				<a href="http://www.pamitc.org/cvpr16">CVPR 2016</a>
                    (<a href="http://cvpr2016.thecvf.com/">outstanding reviewer</a>),
                    <a href="http://www.eccv2016.org">ECCV 2016</a>,
    				<a href="https://nips.cc/Conferences/2016">NIPS 2016</a>
                </li>
                <li> Reviewer for
    				<a href="http://www.pamitc.org/cvpr15">CVPR 2015</a> and
    				<a href="http://pamitc.org/iccv15/">ICCV 2015</a></li>
    			<li>PC member of <a href="http://www.deep-vision.net">CVPR 2016, 2015 and 2014 - Deep Vision Workshop</a></li>
    			<li>PC member of <a href="http://gesture.chalearn.org">CVPR 2015 ChaLearn workshop on Looking at people</a>,
    			 <a href="http://www-rech.telecom-lille.fr/uha3ds2015/">FG 2015 - Human activities workshop</a>.</li>
    		    <li> Area chair for <a href="http://www.avss2014.org">AVSS 2014</a> and <a href="http://www.avss2013.org">AVSS 2013</a></li>
    		    <li>PC member of <a href="http://icmi.acm.org/2014">ICMI 2014</a></li>
    		</ul>
    		    		

		<h3>Miscellaneous:</h3>
		<ul class="sparselist">
			<li>Some of the <a href="teaching/index.html">Teaching Material</a> from my time as associate professor (from 2004 to 2021)</li>
			<li>My <a href="contribution/index.html">most important contribution</a></li>
			<li><a href="motivation/index.html">Passion</a> (other then ML/AI/CV)</li>			
			<li>A short list of some <a href="journalif.html">journal impact factors</a></li>			
			<li><a href="computers/index.html">My personal computing history</a></li>
			
			<li><a href="blue_tiger.html">Blue tiger</a></li>
			<li>My Erdös-Number is 4 (<a href="https://mathscinet.ams.org/mathscinet/freeTools.html?version=2">compute yours</a>), through <a href="https://scholar.google.fr/citations?user=z9FUD8QAAAAJ&hl=fr">Bülent Sankur</a>:<br>
				<div style="margin-left: 4em; margin-top: 1em; font-style: italic;">
				Christian Wolf = 4<br>
				Bülent Sankur = 3<br>
				C. Sinan Güntürk = 2<br>
				Melvyn B. Nathanson = 1<br>
				Paul Erdös = 0
				<div>
			</li>
		</ul>



		<h3>Contact:</h3>

			<p> Email: christian.wolf (at) naverlabs.com<br>
			
			<p style="border-top: 1px solid #bbbbbb;">When your only tool is a hammer, every problem looks like a nail</p>

            <img style="max-width: 100%; max-height: 110vh; height: auto; width: auto\9;" src="miscphotos/footer2023.jpg">

	</div>

	<div class="breaker">
	</div>

</p>
<!-- 
<a href="contribution/yosemite.html">
<img style="max-width: 100%; height: auto; width: auto\9;" src="miscphotos/chris_banner_usa2014_footer.jpg">
</a>

 -->

</body>
</html>
